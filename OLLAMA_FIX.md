# Исправление проблемы с ИИ для инструкций

## Проблема
После изменения модели на `llama3.2:3b` для нормативов, ИИ для инструкций перестал работать, так как он тоже начал использовать эту модель.

## Решение

Добавьте в файл `backend/.env` строку:

```
OLLAMA_INSTRUCTIONS_MODEL=llama3.2:1b
```

Теперь:
- **Инструкции** будут использовать `llama3.2:1b` (быстрая модель)
- **Нормативы** будут использовать `llama3.2:3b` (мощная модель для расчетов)

## Если у вас нет llama3.2:1b

Скачайте её командой:
```bash
ollama pull llama3.2:1b
```

## После изменения .env

Перезапустите backend сервер, чтобы изменения вступили в силу.




